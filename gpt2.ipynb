{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2ce813-1aa6-4a11-aff2-9bae5d28d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\" : 50257, \n",
    "    \"context_length\": 1024, # number of tokens in a single input\n",
    "    \"emb_dim\": 768, # same for both input and output\n",
    "    \"n_heads\": 12, \n",
    "    \"n_layers\": 12, # number of transformer layers\n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466a050e-4104-470e-8aa8-bf4b4d5a7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        ) # transfomer blocks\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"]) # layer norm\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx): # input indices, like token IDs\n",
    "        batch_size, seq_len = in_inx.shape # here seq_len is likely the input context length (1024)\n",
    "        token_embs = self.token_emb(in_idx) # convert token IDs to token embeddings\n",
    "        pos_embs = self.pos_emb(torch.arange(seq_len, device= in_idx.device))\n",
    "        x = token_embs + pos_embs\n",
    "\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x) \n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c278cb-6558-4fca-bb2a-3dffb61db10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e47e6bf-5ac8-4658-970b-9d5e830170c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# implemnting the idea of layer normalization\n",
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ed8d32-de12-40c3-a909-c61bf07caf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:  tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True) # keepdim has to be set to true in order to subtract it from the actual outputs\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Variance: \", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95600662-2073-4668-902c-be8baf3ba5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean)/ torch.sqrt(var) # element-wise subtraction and division\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42083d3a-4706-4cc1-b6e2-67178546ed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60023c93-e1c8-442c-8f49-78d5e2d20ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x): # apply layer normalization followed by scale + shift\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True)\n",
    "\n",
    "        x_norm = (x - mean)/torch.sqrt(var + self.eps) # added self.eps to avoid รท 0\n",
    "        return self.scale * x_norm + self.shift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f71a31-49b4-4d42-8e61-c3ca35314511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.4945,  0.9564, -0.0200,  0.2375, -1.6685],\n",
      "        [ 0.8127, -1.2313, -0.8554,  1.0110,  0.2630]], grad_fn=<AddBackward0>)\n",
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example) # the layer norm itself doesn't change the shape of it's input, it just normalizes it\n",
    "\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Normalized layer outputs:\\n\", out_ln)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe44e64-23ff-4458-9436-60a0d25989f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0/ torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e03e443-d7e7-402f-950a-2fe6b8cc3c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU() # initialize instances\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1): # start enumeration at 1, not zero\n",
    "    plt.subplot(1,2, i)\n",
    "    plt.plot(x,y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3697b5a8-5e90-4dba-9b4c-a088ef2864df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module): # just two layers of weights\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]), \n",
    "            GELU(), \n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c56cb72-d16c-4b5b-8b29-0e35844b64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) # batch size: 2, three input tokens in each batch, and embedding size: 768\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f408135-9c3c-41c2-96d6-7e0272777fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDNN(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape: # also check whether we can add input and output, only then apply the skip connection\n",
    "                x = x + layer_output # add the output of the function to the input to get the layer output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23df74c1-3776-4e56-beec-ef2a077334f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDNN(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape: # also check whether we can add input and output, only then apply the skip connection\n",
    "                x = x + layer_output # add the output of the function to the input to get the layer output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7519a540-175f-4cef-a268-944270bbd27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3,3,3,3,3,1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDNN(layer_sizes, use_shortcut=False) # whenever we initialize a module, we use a \n",
    "# manual seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7be4d55d-3340-466f-b4e5-baaaaee1e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x): # prints the mean absolute gradients for each layer the NN model\n",
    "    y = model(x)\n",
    "    t = torch.tensor([[0.0]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss_value = loss(y, t)\n",
    "\n",
    "    loss_value.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "279862d8-7080-403f-9bac-ddeb90dcdefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152039906941354\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c82917-7b52-44c0-89d8-18febbed93d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDNN(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72fbb1f3-5e24-491e-9bed-c678df0424f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n",
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n",
      "tensor([0.4419, 0.6515, 0.5683])\n",
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.4306, 1.4551])\n",
      "keys.shape torch.Size([6, 2])\n",
      "values.shape torch.Size([6, 2])\n",
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n",
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2, 6, 3])\n",
      "torch.Size([2, 6, 2])\n",
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "Context vectors shape:  torch.Size([2, 6, 4])\n",
      "tensor([[[ 0.1184,  0.3120, -0.0847, -0.5774],\n",
      "         [ 0.0178,  0.3221, -0.0763, -0.4225],\n",
      "         [-0.0147,  0.3259, -0.0734, -0.3721],\n",
      "         [-0.0116,  0.3138, -0.0708, -0.3624],\n",
      "         [-0.0117,  0.2973, -0.0698, -0.3543],\n",
      "         [-0.0132,  0.2990, -0.0689, -0.3490]],\n",
      "\n",
      "        [[ 0.1184,  0.3120, -0.0847, -0.5774],\n",
      "         [ 0.0178,  0.3221, -0.0763, -0.4225],\n",
      "         [-0.0147,  0.3259, -0.0734, -0.3721],\n",
      "         [-0.0116,  0.3138, -0.0708, -0.3624],\n",
      "         [-0.0117,  0.2973, -0.0698, -0.3543],\n",
      "         [-0.0132,  0.2990, -0.0689, -0.3490]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n",
      "context_vecs.shape: torch.Size([1, 1024, 9216])\n"
     ]
    }
   ],
   "source": [
    "from attention2 import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"], \n",
    "            d_out=cfg[\"emb_dim\"], \n",
    "            context_length = cfg[\"context_length\"], \n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            dropout = cfg[\"drop_rate\"], \n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x) # apply layernorm\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x) \n",
    "        x = x + shortcut # add the shortcut connection\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c461fe17-76a6-4557-9c09-641303378b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([2, 4, 768])\n",
      "Output shape:  torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.randn(2, 4, 768)\n",
    "tfblock = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = tfblock(x)\n",
    "\n",
    "print(\"Input shape: \", x.shape)\n",
    "print(\"Output shape: \", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f9b8dba-e600-43a1-8363-2b60e941bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module): # the final abstraction; this is the 124M model\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        ) # transfomer blocks\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"]) # layer norm\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "        # print(self.token_emb.shape, self.out_head.shape)\n",
    "\n",
    "    def forward(self, in_idx): # input indices, like token IDs\n",
    "        batch_size, seq_len = in_idx.shape # here seq_len is different for different inputs; and that's okay\n",
    "        # as long as it is less than the context_length 1024\n",
    "        token_embs = self.token_emb(in_idx) # convert token IDs to token embeddings\n",
    "        pos_embs = self.pos_emb(torch.arange(seq_len, device= in_idx.device)) # perform the lookups for positional embeddings\n",
    "        x = token_embs + pos_embs\n",
    "\n",
    "        x = self.drop_emb(x) # why do we apply dropout here? before even starting the transformer block?\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x) \n",
    "        logits = self.out_head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d69793e-7f66-4b76-b595-964c4beba80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([2, 4])\n",
      "Output shape:  torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "\n",
    "print(\"Input shape: \", batch.shape)\n",
    "print(\"Output shape: \", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb5ddd0f-4edb-4020-a3fc-665cc754e64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paramters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f\"Total number of paramters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "969dc4fa-2d36-4dda-bc31-9c92544d65bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape:  torch.Size([50257, 768])\n",
      "Output layer shape:  torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape: \", model.token_emb.weight.shape)\n",
    "print(\"Output layer shape: \", model.out_head.weight.shape)\n",
    "# given (in, out) shape, nn.Embedding stores it as it is, but nn.Linear stores it transposed, hence the outputs have \n",
    "# the same shape: 50k * 768: That's a lot of parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56988f77-2be9-4556-8c6e-0a8196393441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paramters in GPT 2: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum([p.numel() for p in model.out_head.parameters()])\n",
    "print(f\"Total number of paramters in GPT 2: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeb8652f-fdc7-4897-83a9-1e5af84bf6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention paramters in GPT 2: 28,320,768\n",
      "Feed forward neural network paramters in GPT 2: 56,669,184\n"
     ]
    }
   ],
   "source": [
    "attn_params = sum([p.numel() for p in model.trf_blocks[0].att.parameters()])*12\n",
    "ff_params = sum([p.numel() for p in model.trf_blocks[1].ff.parameters()])*12\n",
    "\n",
    "print(f\"Attention paramters in GPT 2: {attn_params:,}\")\n",
    "print(f\"Feed forward neural network paramters in GPT 2: {ff_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4432e7b2-da52-49bc-b651-0ea0f9d99331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size in bytes: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 # assuming four bytes for each paramter; float32\n",
    "total_size_mb = total_size_bytes / (1024*1024)\n",
    "print(f\"Total size in bytes: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5f2959e-c153-49e1-ad98-9e883005fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paramters in GPT 2 medium: 406,212,608\n",
      "Total number of paramters in GPT 2 large: 838,220,800\n",
      "Total number of paramters in GPT 2 XL: 1,637,792,000\n"
     ]
    }
   ],
   "source": [
    "GPT2_MEDIUM_CONFIG = {\n",
    "    \"vocab_size\" : 50257, \n",
    "    \"context_length\": 1024, # number of tokens in a single input\n",
    "    \"emb_dim\": 1024, # same for both input and output\n",
    "    \"n_heads\": 16, \n",
    "    \"n_layers\": 24, # number of transformer layers\n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "GPT2_LARGE_CONFIG = {\n",
    "    \"vocab_size\" : 50257, \n",
    "    \"context_length\": 1024, # number of tokens in a single input\n",
    "    \"emb_dim\": 1280, # same for both input and output\n",
    "    \"n_heads\": 20, \n",
    "    \"n_layers\": 36, # number of transformer layers\n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "GPT2_XL_CONFIG = {\n",
    "    \"vocab_size\" : 50257, \n",
    "    \"context_length\": 1024, # number of tokens in a single input\n",
    "    \"emb_dim\": 1600, # same for both input and output\n",
    "    \"n_heads\": 25, \n",
    "    \"n_layers\": 48, # number of transformer layers\n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "model_m = GPTModel(GPT2_MEDIUM_CONFIG)\n",
    "model_l = GPTModel(GPT2_LARGE_CONFIG)\n",
    "model_xl = GPTModel(GPT2_XL_CONFIG)\n",
    "\n",
    "total_params_medium = sum([p.numel() for p in model_m.parameters()])\n",
    "total_params_large = sum([p.numel() for p in model_l.parameters()])\n",
    "total_params_xl = sum([p.numel() for p in model_xl.parameters()])\n",
    "\n",
    "print(f\"Total number of paramters in GPT 2 medium: {total_params_medium:,}\")\n",
    "print(f\"Total number of paramters in GPT 2 large: {total_params_large:,}\")\n",
    "print(f\"Total number of paramters in GPT 2 XL: {total_params_xl:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "390403fc-8d0f-4144-8e4e-86c6ade178f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size): # idx has shape (batch_size, num_tokens, \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_context = idx[:, -context_size:] # if the input seq is longer than context_length, crop it from the end\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_context) # has shape (batch_size, num_tokens, vocab_size)\n",
    "    \n",
    "        logits = logits[:, -1, :] # extract the output of the very last token returned; shape (batch_size, vocab_size)\n",
    "        probs = torch.softmax(logits, dim=-1) \n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim=True) # extract the token ID of that last vector; shape (batch_size, 1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # append the output to the old input; shape (batch_size, n_tokens+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4875de85-6c85-4709-bca0-eb3d48edc18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded list:  [15496, 11, 314, 716]\n",
      "encoded_tensor shape:  torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context) # returns a list of encoded token IDs\n",
    "print(\"Encoded list: \", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) # adds a new batch dimension at index 0 \n",
    "print(\"encoded_tensor shape: \", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8445d129-776d-40b5-ae4a-92ceb1e66df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Length of output:  10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model = model, \n",
    "    idx = encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output: \", out)\n",
    "print(\"Length of output: \", out.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a458cca-5d33-41b4-938d-2140aaa4409d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist()) # input to the decoder has to be passed as a list\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c232e5-3dd0-4c38-b980-cd5906e45582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonpackages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
